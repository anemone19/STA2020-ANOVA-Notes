---
title: "Contrasts"
---

```{r setup, echo = FALSE, warning = FALSE}

pyg_data <- read.csv("pygmolian_data.csv")

```

After finding that there evidence to suggest that at least two of the treatments differed from each other, we want to find out which ones and estimate the differences. In the Pygmalion experiment, there was only two treatments so we know the difference is between them. In fact, we could have used a paired t-test to analyse the data and we would get the same results. Generally though, there will be more than two treatments and then after concluding there are differences, the treatment had an effect, we want to know where the differences lie.

To do that, we use the coefficients from fitting a linear regression model to estimate the difference between the two treatments (as we did for CRD experiments as well). The null hypothesis is again:

$$H_0: \mu_C - \mu_P = 0 $$

where C stands for Control and P for Pygmalion. We use the `lm` function as in regression.

::: column-margin
We use the `lm` function when we are primarily interested in the coefficient estimates and difference. We use `aov()` when we want a breakdown of how much each factor can explain of the overall variation in the response, and when we want a general test for 'are there *any* difference between the treatments'.
:::

```{r}

pyg_model_reg <- lm(Score ~ Treat + Company, data = pyg_data)
summary(pyg_model_reg)

```

A few things to note here.

1.  We are only interested in the second line starting with `TreatPygmalion`. R pasted the name of the factor and the name of the treatment level together.

2.  The Control treatment was taken as the baseline (it comes first in the alphabet).

3.  The remaining lines are not of interest to us. It estimates the differences between each block and the first and test whether these effects are different from zero. R doesn't know we aren't interested in these, so it computes the effects and hypothesis test as if we are. We ignore this part.

4.  If we didn't know that this code was for analysing a RCBD we would probably think that it is linear regression with two categorical variables. Think back to the regression module, what does this intercept represent? It represents the mean score for some treatment level and company. Since 'C' comes before 'P' in the alphabet and C1 is before everything else, the intercept is the average score for the control group in the first block. This is because R uses the *treatment contrast* parameterisation by default for all the factors. We can change this by letting R know that the block effects sum to zero.

```{r}

pyg_model_reg2 <- lm(Score ~ Treat + C(as.factor(Company), contr.sum), data = pyg_data)
summary(pyg_model_reg2)

```

Now, the intercept is what we expect, the mean score for the control treatment across all blocks.

```{r}
mean(pyg_data$Score[pyg_data$Treat == "Control"])

```

Let's interpret the hypothesis test for the difference between treatment means. The estimated difference is 10.78 with a standard error of 3.126. The test statistic is 3.448 which has a p-value of 0.00729. Look familiar? It's the exact same p-value we found with the ANOVA! That is because the ANOVA is an extension of the t-test to more than two groups and when we only have two treatments, they are equivalent. In fact, the test statistics have the following relationship:

$$ t^2 = F$$ 

Test it out to see that it holds. Back to the interpretation. The test tells us that the difference between the control and Pygmalion treatment is significant since the p-value is extremely small indicating that we have strong evidence against the null hypothesis of equal means.
