# A Simple Model for a CRD

To analyse data collected from a Completely Randomised Design we could use t-tests and compare the samples two at a time. This approach is problematic for two reasons. Firstly, the test statistic of a t-test is calculated with a standard deviation of the differences between means based only on the two samples it considers and not the other samples collected in the experiment. We want our test statistic to consider the variability in all samples. Second, when we conduct multiple tests the overall Type 1 Error rate increases. That is, when doing many tests, the chance of making *at least one wrong conclusion* increases with the number of tests (if you want to know more see the box below). To avoid this, we will use the ANOVA method which was specifically developed for comparing multiple means. 

:::{.callout-caution icon="false" collapse = "true"}

## Multiple Testing / Comparisons {.unnumbered}

When we conduct a test, there is always a chance that a signficant result is due to chance and not actually a real difference. In first year, you were taught the Neyman-Pearson approach to hypothesis testing, which entails setting a significance level ($\alpha$) for the test you will conduct. This signficance level is the Type 1 error rate (probability of falsely rejecting $H_0$). A common $\alpha$ is 0.05, meaning that 5% of the time we will reject the null hypothesis even if it is true. So when we find a significant result, one of two things have happened: 

1. Either we genuinely found a significant result or, 
2. We were that unlucky, that our result is one of those 5% cases. 

We will never know, this is the basis of statistical testing. We accept that we cannot tell which of our conclusions are type 1 errors. When we conduct many tests, the overall Type 1 Error rate increases. That is the overall chance of *at least one wrong conclusion* increases with the number of tests conducted. This is not good! We already might be wrong 5% and we don't want to increase that risk even further when conducting multiple tests. 

::: 

When we collect data and want test something about it's distribution, we can always develop a model for the observations which reflect the different sources of variations believed to be at a play. 

Maybe add more about statistical modelling 


The ANOVA model is similar to a regression model in that they are also linear models, but, because we mostly deal with categorical explantory variables (the treatments), a slightly different notation is convenient. 


The most common model for a single factor CRD is

$$ Y_{ij} = \mu + A_{i} + e_{ij} $$ 

where 

\begin{equation}
\begin{aligned}
i & = 1, \dots, a \quad (a = \text{number of treatments}) \\
j & = 1, \dots, r \quad (r = \text{number of replicates}) \\
Y_{ij} & = \text{observation of the } j^{th} \text{ unit receiving treatment } i \\
\mu & = \text{overall or general mean} \\
A_i & = \text{effect of the } i^{th} \text{ level of treatment factor A} \\
e_{ij} & = \text{random error with } e_{ij} \sim N(0, \sigma^2)
\end{aligned}
\end{equation}

In our example, the factor A is level of multitasking with $a = 3$ levels and $r$ is 40. The above model is often called Model I. 


:::{.callout-caution icon="false" collapse = "true"}

## Comparison to regression model. 

If you wanted to you could rewrite this with the regression notation you've encounter before as a regression model with a single categorical explanatory variables: 

$$ Y_i = \beta_0 + \beta_1 T2_i + \beta_2 T3_i + e_i $$

where $T2$ and $T3$ are indicator variables (i.e. T2 = 1 if observaton i is from treatment 2 and 0 otherwise). The intercept estimates the mean of the baseline category, here it is T1.

These two models are equivalent. The data are the exactly the same: in both sitautions we have $a$ groups and we are interetsed in the mean response of these groups and the difference between them. The model notation is just slightly different. In the ANOVA model we use $\mu$ and $A_i$ instead of $\beta_0$ and $\beta_i$ which have different meanings. 

| Regression  | ANOVA       |
|:-----------:|:-----------:|
|     $\beta_0$ is the mean of the baseline category      |     $\mu$ is the overall mean      |    
|     $\beta_1$ is the difference between the means of category 2 and the baseline category.      |     $A_i$ is the effect of treatment $i$, i.e. change in mean response relative to the overall mean.       |    
\

When all the explanatory variables are categorical, which is mostly the case in experimental data, it is more conveniet to write the model in the ANOVA form, for two reasons:

1. The $A_i$ notation is more concise, becasue we don't have to add all the dummy variables. This makes it easier to read and understand becasue there is only term per factor. 

2. Mathmatically it is more convenient. in this format all terms are deviations from a mean. This leads directly to sums of sqaures (squared deviations from a mean) and analysis of variance. We will see later that we can partition the total sum of sqaures, one part for every factor in the model. This allows us to investigate the variability in the response contrbuted by every model term (or factor). 
:::

The above ANOVA model implies $a$ population means corresponding to the $a$ treatments: $\mu_1, \mu_2, \mu_3, \ldots, \mu_a$. 




