{
  "hash": "1df3b3dd0a29674db9311ae4f1f20be5",
  "result": {
    "engine": "knitr",
    "markdown": "## Contrasts \n\n\n\n\n\n\n\n\n\n\n\n\nThere are two approaches to analysing data from experiments. The first is to construct a set of a-priori contrasts, test these, and perhaps afterwards use unplanned comparisons to see if there are any other interesting treatment effects or differences that we might want to follow up with in a future experiment.\n\nThe second approach is an analysis of variance (ANOVA). This usually tests much more general hypotheses about the presence of main and interaction effects. The two approaches are not mutually exclusive, but if the questions we are interested in are not answered by an analysis of variance, we should concentrate on the contrasts. The two approaches may also give what seem to be different answers.  \n\nFor example, from the ANOVA F-test, we may see no evidence for interactions, but if we look at specific contrasts for interactions, there is evidence. This can happen; it is not a mistake in the methods, it is just a difference in the hypotheses that are being tested.\n\nOften, an ANOVA is expected in journal publications and research reports, even if it does not answer the specific research questions. The more specific questions are answered by constructing confidence intervals or tests for contrasts.\n\nLet's revisit the specific research questions for the working example: \n\n1.  Does lecture modality have an effect on comprehension?\n2.  Does playback speed have an effect on comprehension?\n3.  Is there an interaction effect of modality and playback speed on comprehension?\n\nWith these question, conducting an ANOVA is enough. We simply want to know if there are any main effects or interaction effects. We have answered that with the ANOVA above. But what if the questions were a bit more specific: \n\n1.  Does audio-visual content increase comprehension?\n2.  Does increased playback speed decrease comprehension?\n3.  Is the effect of playback speed improved by audio-visual content?\n\nSo far we have only contrasted two treatments. Sometimes we want to compare groups of treatments to one another. More generally, a contrast is defined as a linear combination of the parameters where the coefficients add up to zero:\n\n$$L = \\sum_1^a h_iA_i$$ \n\nsuch that $\\sum_1^a h_i = 0$. This ensures a fair comparison. For example, in a compairson of two group means we have:\n\n$$ L = \\mu_1 - \\mu_2 = 1\\times \\mu + (-1) \\times \\mu_2$$ \nHere, the coefficients are $h_1 = +1$ and $h_2 = -1$ which sum to zero. This simple difference is the simplest form of a contrast. Effectively, $\\sum_1^a h_i = 0$ represents the null hypothesis, that the difference equals 0. \n\nLet's start with the first question. Remeber the treatments were: \n\n1. 1x Audio-Only (1AO)\n2. 2x Audio-Only (2AO)\n3. 1x Audio-Visual (1AV)\n4. 2x Audio-Visual (2AV)\n\nTo answer the first question, our contrast should compare Audio-Visual vs. Audio-Only and we do this by averaging over the levels of playback speed. \n\n\nFirst we compute the average response for the two levels of content type, AV and AO. \n\n$$\\frac{(\\mu_{1AV} + \\mu_{2AV})}{2}$$\n\n$$\\frac{(\\mu_{1AO} + \\mu_{2AO})}{2}$$\n\nNow we are comparing groups of means. The first group contains the means for all treatments that included Audio-Visual level and the second contains the Audio-Only level. We are asking whether the AV level increased comprehension. So we are testing: \n\n:::{.column-margin}\n\nWe could specify the difference either way, that is AO - AV. Then we would be doing a one-sided lower tailed test. \n\n:::\n\n$$H_0: \\frac{(\\mu_{1AV} + \\mu_{2AV})}{2} = \\frac{(\\mu_{1AO} + \\mu_{2AO})}{2}$$\n\n$$\nH_1: \\frac{(\\mu_{1AV} + \\mu_{2AV})}{2} > \\frac{(\\mu_{1AO} + \\mu_{2AO})}{2} <=> \\frac{(\\mu_{1AV} + \\mu_{2AV})}{2} - \\frac{(\\mu_{1AO} + \\mu_{2AO})}{2} > 0\n$$\n\n\nThe coefficients of the contrast sum to zero:  \n\n$$\n\\begin{aligned}\n&\\frac{(\\mu_{AV1} + \\mu_{AV2}) - (\\mu_{AO1} + \\mu_{AO2})}{2} \\\\\n&\\frac{(1) \\mu_{AV1} + (1) \\mu_{AV2} + (-1) \\mu_{AO1} + (-1) \\mu_{AO2}}{2} \\\\ \n& (0.5) \\mu_{AV1} + (0.5) \\mu_{AV2} + (-0.5) \\mu_{AO1} + (-0.5) \\mu_{AO2} \\\\\n&0.5+.0.5-0.5-0.5 = 0\n\\end{aligned}\n$$\nThis is a linear combination of the model parameters. What does the contrast and coefficients look like for the second question? To test whether playback speed decreases comprehension, we need to compare treatments at 1x speed vs. 2x speed:\n\n$$\\frac{(\\mu_{1AV} + \\mu_{1AO})}{2} - \\frac{(\\mu_{2AO} + \\mu_{2AV})}{2}$$\nThe coefficients sum to zero as before. This might be confusing but we are simply grouping treatments together and comparing them. To compute these contrasts in R, we first fit the model using lm() and extract the treatment means using `emmeans` from the `emmeans` package.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_reg <- lm(Accuracy ~ Content.Type * Speed, data = data)\n\nmeans <- emmeans(model_reg, ~Content.Type * Speed)\n\nmeans\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Content.Type Speed emmean   SE  df lower.CL upper.CL\n Audio-Only       1   50.3 2.11 196     46.2     54.5\n Audio-Visual     1   59.6 2.11 196     55.4     63.7\n Audio-Only       2   47.9 2.11 196     43.7     52.0\n Audio-Visual     2   53.4 2.11 196     49.2     57.5\n\nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n\n\n\nThe `emmeans` function returns the treatment means, the standard error, degrees of freedom and the bounds of 95% confidence interval. Now we want to perform the two contrasts using the means saved in the object we created, `means`. First, note the order in which `emmeans` outputs the treatments: \n\nAO1, AV1, A02, AV2. \n\nWe are going to use this order and the coefficients were determined earlier to perform the ocntrasts with the function `contrast()` also from the package `emmeans`: \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrast(means,\n         list(\n           c1 = c(-1,1,-1,1)/2, # AV - AO\n           c2 = c(1,1,-1,-1)/2 # 2x - 1x\n         ),\n         by = NULL, side = \">\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast estimate   SE  df t.ratio p.value\n c1           7.36 2.11 196   3.492  0.0003\n c2           4.32 2.11 196   2.050  0.0209\n\nP values are right-tailed \n```\n\n\n:::\n:::\n\n\n\n\n\nWe supply the emmeans object `means` and then a list of contrasts we call `c1` and `c2` corresponding to the first and second question. Each contrast consists of the coefficients in the order in which the means appear in the `means` object and the scaling by 2. Then we need to specify `by = NULL` because we have manually coded the contrasts and don't need to specify by which factor the contrasts should made. Lastly, we specify the type of test we want, that is, is it one sided or two sided. If it is one-sided, in which direction? We have specifically constructed the contrasts so that both are \"one-sided greater than\". \n\nThe output shows the estimate of each contrast, the standard error of the difference in means, t-value and associated p-value. For the first contrast we see the difference in comprehesion scores between the Audio-Vsual and Audio-Only groups was 7.36, this means that the avearge response in the Audio-Visual group was higher than the average response in the Audio-Only group. We see that the p-value to test this contrast is 0.0003 which is extremely small, so it is unlikely that the difference in mean response is due to chance. There is strong evidence to indicate that the audio-visual type increased the mean response, the estimate of this the difference between groups is 7.36% ($t=3.492$, $df = 196$, $p = 0.0003$).  \n\nFor the second contrast, the p-value still provides sufficient evidence against the null hypothesis that the difference is zero but it is not as strong as for the first contrast. However, we are still satisfied with the evidence against $H_0$. The 2x speed decreased the average accuracy (averaged over the levels of content type) by 4.32% ($t=-2.050$, $df = 196$, $p = 0.021$). \n\nWhen we have factors with two levels (as we do here) and we conduct two sided contrasts, then the contrast is equivalent to testing for the presence of main effects which what the ANOVA table does! Remember we said that the ANOVA is an extension of the t-test and with two levels. Let's go through this step-by-step: \n\n- We conducted one-sided tests. \n- If we conducted two-sided tests, the results would be the same as in ANOVA table. \n- This is because when we have two levels per treatment factor, the contrasts are equivalent to testing whether there are main effects of Speed and Content.Type. \n\nSince we conducted one-sided tests, the p-value is has been split between the tails. To get to the value of the p-value for a two-sided tests, we multiply the one-sided p-value by 2. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# For AV - AO = 0\n\n0.0003*2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6e-04\n```\n\n\n:::\n\n```{.r .cell-code}\n# For 1 - 2 = 0\n\n0.0209 * 2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0418\n```\n\n\n:::\n:::\n\n\n\n\n\nCheck that these are the same as in the ANOVA table. The test statistics are also related in this case, $t^2 = F$. \n\nLet's answer the third question. Since we have two levels per factor, this question is asking about the interaction. The contrast for the interaction should compare the *difference between audio-visual and audio-only in the two levels of playback speed*:\n\nAt 1x playback speed, the effect of content type is given by:\n\n$$\n(\\mu_{AV1} - \\mu_{AO1})\n$$\n\nAt 2x playback speed, the effect of content type is given by:\n\n$$\n(\\mu_{AV2} - \\mu_{AO2})\n$$\n\nNow to examine whether the effect of content type is consistent across playback speeds, we compute:\n\n$$\n\\begin{aligned}\n&(\\mu_{AV1} - \\mu_{AO1}) - (\\mu_{AV2} - \\mu_{AO2})\\\\\n& = \\mu_{AV1} - \\mu_{AO1} - \\mu_{AV2} + \\mu_{AO2}\n\\end{aligned}\n$$\n\nThis contrast assesses whether the difference between Audio-Visual and Audio-Only is the same at 1x and 2x speeds. \n\n:::{.column-margin}\n\nWe are not dividing by two because we are not averaging across conditions, we are computing the difference of two differences.\n\n:::\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrast(means,\n         list(\n           c3 = c(-1, 1, 1,-1) # interaction\n         ),\n         by = NULL)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast estimate   SE  df t.ratio p.value\n c3           3.76 4.22 196   0.892  0.3735\n```\n\n\n:::\n:::\n\n\n\n\n\nWe get the same p-value as in the ANOVA table which indicates a lack of evidence against the null hypothesis, there is no evidence to suggest that the two factors interact ($t=0.892$, $df = 196$, $p = 0.374$).  \n\nIn practice, we would test the interaction first and then interpret the main effects if there is evidence to support their presence. Here we have done it this way around purely for educational purposes. \n\nWe can also visualise the interaction (especially useful for understanding the interaction if there is evidence for one!). There is a built-in function in R that can do this for us, but it will be useful to construct the plot from scratch to ensure you understand what it visualises. \n\n\nHave a look at the dataset again. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Participant.ID       Condition Speed Content.Type Accuracy\n1     945445adf5 1x Audio-Visual     2 Audio-Visual       42\n2     23afb88ef3        1x Audio     1   Audio-Only       56\n3     1bc24e0480        1x Audio     1   Audio-Only       62\n4     4fbdbd41a5        1x Audio     1   Audio-Only       44\n5     442adf227a        1x Audio     1   Audio-Only       56\n6     3ca9d09e2e 1x Audio-Visual     2 Audio-Visual       48\n```\n\n\n:::\n:::\n\n\n\n\n\nWe want to visualise the response per treatment for each combination of Speed and Content.Type (which is already combined in the column Condition). We did this with the `emmeans` function and stored the treatment means in the object `means`! To use it to visualsie the treatment means we need to convert to a dataframe, currently it is something called a \"emmGrid\"\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeans \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Content.Type Speed emmean   SE  df lower.CL upper.CL\n Audio-Only       1   50.3 2.11 196     46.2     54.5\n Audio-Visual     1   59.6 2.11 196     55.4     63.7\n Audio-Only       2   47.9 2.11 196     43.7     52.0\n Audio-Visual     2   53.4 2.11 196     49.2     57.5\n\nConfidence level used: 0.95 \n```\n\n\n:::\n\n```{.r .cell-code}\nclass(means)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"emmGrid\"\nattr(,\"package\")\n[1] \"emmeans\"\n```\n\n\n:::\n:::\n\n\n\n\nIt is easy to convert the obejct to a dataframe: \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeans_data <- data.frame(means)\n```\n:::\n\n\n\n\n\nWe need to decide which factor will be on the x-axis, let's do Speed. Below, I use a new package called `ggplot2` to visualise the data. It creates nicer looking plots and is more intutiive in my opinion. If you want to see how to use base R to plot this, see the code at the end of this section. \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"ggplot2\")\nlibrary(ggplot2)\n\n# Create the ggplot with interaction lines\nggplot(means_data, aes(x = factor(Speed), y = emmean, colour = Content.Type, group = Content.Type)) +\n  geom_point(size = 3) +     # Add points for each Content Type\n  geom_line(linewidth = 1) +      # Connect points with lines\n  labs(title = \"Interaction Plot: Speed vs Content Type\",\n       x = \"Speed\",\n       y = \"Mean Response\") +\n  scale_y_continuous(limits =c(35,65)) + # to visualse the magnitude a bit better\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](17_FE_Contrasts_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\n\nThe `aes()` function maps Speed to the x-axis, Mean Response to the y-axis, and uses Content Type for color and grouping. `geom_point(size = 3)` adds individual data points, while `geom_line(size = 1)` connects them to show trends. The `labs()` function provides axis labels and a title, and `theme_minimal()` specifies the theme for the plot. \n\n:::{.column-margin}\n\nIf you want to know more about how to visualise data with `ggplot2` have a look at this [link](https://ggplot2.tidyverse.org/). There are plenty of resources mentioned. \n\n:::\nIt is evident that increasing Speed has a negative effect on the response, and switching from Audio-Visual to Audio-Only content reduces the mean response. When moving from 1x to 2x Speed in the Audio-Visual condition, the response decreases. A similar decline is observed for the Audio-Only condition. Although the decrease appears slightly larger for Audio-Visual than for Audio-Only, the difference is not substantial enough to conclude a significant interaction effect between Speed and Content Type as evidenced by the ANOVA and contrasts we did before. \n\n\n## Conclusion \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Set up an empty plot\nplot(means_data$Speed[means_data$Content.Type == \"Audio-Visual\"], \n     means_data$emmean[means_data$Content.Type == \"Audio-Visual\"], \n     type = \"o\", \n     col = \"#F79256\", \n     pch = 16, \n     ylim = range(means_data$emmean), \n     xlab = \"Speed\", \n     ylab = \"Mean Response\", \n     main = \"Interaction Plot: Speed vs Content Type\",\n     xaxt = \"n\")\n\n# - plot(...) initializes the graph using Speed as the x-axis and Mean Response as the y-axis.\n# - The subset `means_data$Speed[means_data$ContentType == \"Audio-Visual\"]` extracts only Audio-Visual data to plot the first line.\n# - type = \"o\" specifies that both points and lines should be drawn.\n# - ylim = range(means_data$emmean) ensures that the y-axis spans the full range of data.\n# - xaxt = \"n\" suppresses the default x-axis, allowing for manual customization in the next step.\n# \n# Since the x-axis represents discrete categories (Speed levels), we manually specify the tick labels with the function `axis` and then we overlay the means for the Audio-Only groups with `points`. Lastly, we add a legend. \n\n# Add x-axis labels manually\naxis(1, at = unique(as.numeric(means_data$Speed)), labels = unique(means_data$Speed))\n\n# Add Audio-Only group\npoints(means_data$Speed[means_data$Content.Type == \"Audio-Only\"], \n       means_data$emmean[means_data$Content.Type == \"Audio-Only\"], \n       col = \"#5BC0EB\", \n       pch = 16, \n       type = \"o\")\n\n# Add legend\nlegend(\"topright\", legend = c(\"Audio-Visual\", \"Audio-Only\"), col = c(\"#F79256\", \"#5BC0EB\"), pch = 16, lty = 1)\n```\n\n```{.r .cell-code  code-fold=\"true\"}\n# OR WITH BUILT IN \n\ninteraction.plot(x.factor = means_data$Speed, #x-axis variable\n                 trace.factor = means_data$Content.Type, #variable for lines\n                 response = means_data$emmean, #y-axis variable\n                 fun = mean, #metric to plot\n                 ylab = \"Counts\",\n                 xlab = \"Seasons\",\n                 col = c(\"red\", \"blue\"),\n                 lty = 1, #line type\n                 lwd = 2, #line width\n                 trace.label = \"Species\")\n```\n:::\n",
    "supporting": [
      "17_FE_Contrasts_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}